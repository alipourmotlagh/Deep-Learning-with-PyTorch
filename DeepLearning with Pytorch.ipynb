{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDFVd-WfsEKx"
      },
      "source": [
        "# DeepLearning with Pytorch\n",
        "DataCamp Course"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NoMYOiXusEKy"
      },
      "outputs": [],
      "source": [
        "# pip install torch\n",
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyzwAgFAsrUU"
      },
      "source": [
        "## Creating tensors in PyTorch\n",
        "Random tensors are very important in neural networks. Parameters of the neural networks typically are initialized with random weights (random tensors).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2, 3, 5],\n",
              "        [1, 2, 9]])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list1=[2,3,5]\n",
        "list2=[1,2,9]\n",
        "torch.tensor([list1,list2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[2, 3, 5],\n",
              "       [1, 2, 9]])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.array([list1,list2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2.0166, 1.7149, 2.0680, 1.8962],\n",
              "        [2.0816, 1.6449, 2.0028, 1.6407],\n",
              "        [1.3223, 1.2938, 1.4979, 1.3945],\n",
              "        [1.0873, 0.7426, 0.9934, 0.9451]])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#multiplcation with pytorch\n",
        "mat1=torch.rand(4,4)\n",
        "mat2=torch.rand(4,4)\n",
        "multmat=torch.matmul(mat1,mat2)\n",
        "multmat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.2267, 0.4928, 0.4918, 0.6619],\n",
              "        [0.0953, 0.0612, 0.2552, 0.5078],\n",
              "        [0.9405, 0.1405, 0.2718, 0.3306],\n",
              "        [0.0960, 0.7073, 0.4608, 0.1454]])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#element multiplication\n",
        "mat1 * mat2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1.12754878, 0.85733287, 1.23747869, 1.0127282 ],\n",
              "       [1.07296251, 1.16571859, 1.19272448, 1.14941114],\n",
              "       [1.39294344, 0.83636715, 1.39027568, 1.04029302],\n",
              "       [0.9928961 , 0.31433012, 0.88691205, 0.87661795]])"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#multiplication with Numpy\n",
        "mat1=np.random.rand(4,4)\n",
        "mat2=np.random.rand(4,4)\n",
        "multmat=np.dot(mat1,mat2)\n",
        "multmat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.27535674, 0.92081175, 0.38278094, 0.51026539],\n",
              "       [0.15748971, 0.14487037, 0.05340088, 0.03931516],\n",
              "       [0.21510058, 0.01592962, 0.13466538, 0.68922102],\n",
              "       [0.07689088, 0.03990748, 0.68427285, 0.15047132]])"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#element multiplication\n",
        "np.multiply(mat1,mat2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0.],\n",
              "        [0., 0.]])"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.zeros(2,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 1.],\n",
              "        [1., 1.]])"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.ones(2,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 0.],\n",
              "        [0., 1.]])"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.eye(2,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 0.],\n",
              "       [0., 0.]])"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.zeros((2,2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1., 1.],\n",
              "       [1., 1.]])"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.ones((2,2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1., 0.],\n",
              "       [0., 1.]])"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.identity(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 0.],\n",
              "        [0., 1.]], dtype=torch.float64)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.from_numpy(np.identity(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1., 0.],\n",
              "       [0., 1.]], dtype=float32)"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.eye(2,2).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "nOvj-7v_sEKz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.4598, 0.6097, 0.8728],\n",
            "        [0.6495, 0.0638, 0.8282],\n",
            "        [0.6361, 0.8120, 0.2330]])\n",
            "torch.Size([3, 3])\n"
          ]
        }
      ],
      "source": [
        "# Create random tensor of size 3 by 3\n",
        "your_first_tensor = torch.rand(3, 3)\n",
        "\n",
        "# Calculate the shape of the tensor\n",
        "tensor_size = your_first_tensor.shape\n",
        "\n",
        "# Print the values of the tensor and its shape\n",
        "print(your_first_tensor)\n",
        "print(tensor_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EKamNVAHtUGl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.74010236 0.80915197 0.84563443]\n",
            " [0.9775519  0.93318597 0.34364613]\n",
            " [0.58134982 0.33891279 0.75384948]]\n",
            "(3, 3)\n"
          ]
        }
      ],
      "source": [
        "#same things in Numpy\n",
        "# Create random tensor of size 3 by 3\n",
        "your_first_tensor = np.random.rand(3, 3)\n",
        "\n",
        "# Calculate the shape of the tensor\n",
        "tensor_size = your_first_tensor.shape\n",
        "\n",
        "# Print the values of the tensor and its shape\n",
        "print(your_first_tensor)\n",
        "print(tensor_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "tensor([[1., 0., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 0., 1.]])\n"
          ]
        }
      ],
      "source": [
        "# Create a matrix of ones with shape 3 by 3\n",
        "tensor_of_ones = torch.ones(3, 3)\n",
        "\n",
        "# Create an identity matrix with shape 3 by 3\n",
        "identity_tensor = torch.eye(3)\n",
        "\n",
        "# Do a matrix multiplication of tensor_of_ones with identity_tensor\n",
        "matrices_multiplied = torch.matmul(tensor_of_ones, identity_tensor)\n",
        "print(matrices_multiplied)\n",
        "\n",
        "# Do an element-wise multiplication of tensor_of_ones with identity_tensor\n",
        "element_multiplication = tensor_of_ones*identity_tensor\n",
        "print(element_multiplication)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Forward pass\n",
        "Let's have something resembling more a neural network. The computational graph has been given below. You are going to initialize 3 large random tensors, and then do the operations as given in the computational graph. The final operation is the mean of the tensor, given by torch.mean(your_tensor)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(124903.4922)\n"
          ]
        }
      ],
      "source": [
        "# Initialize tensors x, y and z\n",
        "x = torch.rand(1000, 1000)\n",
        "y = torch.rand(1000, 1000)\n",
        "z = torch.rand(1000, 1000)\n",
        "\n",
        "# Multiply x with y\n",
        "q = torch.matmul(x,y)\n",
        "\n",
        "# Multiply elementwise z with q\n",
        "f = torch.matmul(z,q)\n",
        "\n",
        "mean_f = torch.mean(f)\n",
        "print(mean_f)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Backpropagation using PyTorch\n",
        "Here, you are going to use automatic differentiation of PyTorch in order to compute the derivatives of x, y and z from the previous exercise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradient of x is: tensor([5.])\n",
            "Gradient of y is: tensor([5.])\n",
            "Gradient of z is: tensor([1.])\n"
          ]
        }
      ],
      "source": [
        "# Initialize x, y and z to values 4, -3 and 5\n",
        "x = torch.tensor([4.], requires_grad=True)\n",
        "y = torch.tensor([-3.], requires_grad=True)\n",
        "z = torch.tensor([5.],requires_grad=True)\n",
        "\n",
        "# Set q to sum of x and y, set f to product of q with z\n",
        "q = x+y\n",
        "f = z*q\n",
        "\n",
        "# Compute the derivatives\n",
        "f.backward()\n",
        "\n",
        "# Print the gradients\n",
        "print(\"Gradient of x is: \" + str(x.grad))\n",
        "print(\"Gradient of y is: \" + str(y.grad))\n",
        "print(\"Gradient of z is: \" + str(z.grad))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradient of x is: tensor([[0.0369, 0.0832, 0.0617, 0.0362, 0.0575],\n",
            "        [0.0272, 0.0662, 0.0526, 0.0201, 0.0468],\n",
            "        [0.0314, 0.0524, 0.0506, 0.0233, 0.0362],\n",
            "        [0.0404, 0.0694, 0.0546, 0.0346, 0.0411],\n",
            "        [0.0502, 0.0981, 0.0724, 0.0492, 0.0614]])\n",
            "Gradient of y is: tensor([[0.0146, 0.0329, 0.0225, 0.0174, 0.0582],\n",
            "        [0.0340, 0.0607, 0.0403, 0.0430, 0.0698],\n",
            "        [0.0208, 0.0590, 0.0275, 0.0396, 0.0709],\n",
            "        [0.0297, 0.0624, 0.0313, 0.0420, 0.0726],\n",
            "        [0.0361, 0.0546, 0.0356, 0.0344, 0.0568]])\n",
            "Gradient of z is: tensor([[0.0513, 0.0290, 0.0379, 0.0631, 0.0400],\n",
            "        [0.0727, 0.0228, 0.0439, 0.0709, 0.0547],\n",
            "        [0.0512, 0.0315, 0.0299, 0.0658, 0.0479],\n",
            "        [0.0463, 0.0299, 0.0333, 0.0766, 0.0508],\n",
            "        [0.0452, 0.0268, 0.0206, 0.0545, 0.0501]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/vv/qbkrt9vj4_j3xx714txsmc900000gn/T/ipykernel_35770/1950033724.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(torch.rand(5,5).requires_grad_(True), requires_grad=True)\n",
            "/var/folders/vv/qbkrt9vj4_j3xx714txsmc900000gn/T/ipykernel_35770/1950033724.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  y = torch.tensor(torch.rand(5,5).requires_grad_(True), requires_grad=True)\n",
            "/var/folders/vv/qbkrt9vj4_j3xx714txsmc900000gn/T/ipykernel_35770/1950033724.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  z = torch.tensor(torch.rand(5,5).requires_grad_(True),requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor(torch.rand(5,5).requires_grad_(True), requires_grad=True)\n",
        "y = torch.tensor(torch.rand(5,5).requires_grad_(True), requires_grad=True)\n",
        "z = torch.tensor(torch.rand(5,5).requires_grad_(True),requires_grad=True)\n",
        "\n",
        "# Multiply tensors x and y\n",
        "q = torch.matmul(x,y)\n",
        "\n",
        "# Elementwise multiply tensors z with q\n",
        "f = z*q\n",
        "\n",
        "mean_f = torch.mean(f)\n",
        "\n",
        "# Calculate the gradients\n",
        "mean_f.backward(\n",
        ")\n",
        "print(\"Gradient of x is: \" + str(x.grad))\n",
        "print(\"Gradient of y is: \" + str(y.grad))\n",
        "print(\"Gradient of z is: \" + str(z.grad))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradient of x is: tensor([[0.0755, 0.0561, 0.0606, 0.0362, 0.0649],\n",
            "        [0.0520, 0.0480, 0.0531, 0.0306, 0.0609],\n",
            "        [0.0453, 0.0250, 0.0357, 0.0294, 0.0422],\n",
            "        [0.0562, 0.0487, 0.0378, 0.0312, 0.0575],\n",
            "        [0.0488, 0.0342, 0.0329, 0.0309, 0.0491]])\n",
            "Gradient of y is: tensor([[0.0464, 0.0463, 0.0470, 0.0182, 0.0586],\n",
            "        [0.0421, 0.0675, 0.0426, 0.0236, 0.0686],\n",
            "        [0.0525, 0.0474, 0.0281, 0.0176, 0.0616],\n",
            "        [0.0366, 0.0522, 0.0339, 0.0172, 0.0556],\n",
            "        [0.0630, 0.0646, 0.0550, 0.0230, 0.0798]])\n",
            "Gradient of z is: tensor([[0.0466, 0.0629, 0.0400, 0.0655, 0.0406],\n",
            "        [0.0329, 0.0615, 0.0350, 0.0400, 0.0466],\n",
            "        [0.0416, 0.0694, 0.0289, 0.0455, 0.0471],\n",
            "        [0.0391, 0.0600, 0.0481, 0.0740, 0.0505],\n",
            "        [0.0298, 0.0435, 0.0390, 0.0342, 0.0268]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.rand(5,5).clone().detach().requires_grad_(True)\n",
        "y = torch.rand(5,5).clone().detach().requires_grad_(True)\n",
        "z = torch.rand(5,5).clone().detach().requires_grad_(True)\n",
        "\n",
        "# Multiply tensors x and y\n",
        "q = torch.matmul(x,y)\n",
        "\n",
        "# Elementwise multiply tensors z with q\n",
        "f = z*q\n",
        "\n",
        "mean_f = torch.mean(f)\n",
        "\n",
        "# Calculate the gradients\n",
        "mean_f.backward(\n",
        ")\n",
        "print(\"Gradient of x is: \" + str(x.grad))\n",
        "print(\"Gradient of y is: \" + str(y.grad))\n",
        "print(\"Gradient of z is: \" + str(z.grad))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction to Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net,self).__init__()\n",
        "        self.fc1=nn.Linear(10,20)\n",
        "        self.fc2=nn.Linear(20,20)\n",
        "        self.output=nn.Linear(20,4)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x=self.fc1(x)\n",
        "        x=self.fc2(x)\n",
        "        x=self.output(x)\n",
        "        return x"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Your first neural network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_layer=torch.tensor([0.6274, 0.1628, 0.0105, 0.6633, 0.8410, 0.9622, 0.5430, 0.1063, 0.9469,\n",
        "        0.6349, 0.4724, 0.8962, 0.4189, 0.1548, 0.1493, 0.8707, 0.5688, 0.5573,\n",
        "        0.0200, 0.0686, 0.4835, 0.6485, 0.6707, 0.4840, 0.3334, 0.4511, 0.9080,\n",
        "        0.7644, 0.1195, 0.2261, 0.7179, 0.0761, 0.3053, 0.4166, 0.5864, 0.7685,\n",
        "        0.1430, 0.5032, 0.7597, 0.0178, 0.6681, 0.7929, 0.2807, 0.4565, 0.8951,\n",
        "        0.9561, 0.7653, 0.6765, 0.9817, 0.6979, 0.7538, 0.9748, 0.7861, 0.9306,\n",
        "        0.9722, 0.9187, 0.8236, 0.9616, 0.7018, 0.0258, 0.0731, 0.9699, 0.7713,\n",
        "        0.4656, 0.9950, 0.3696, 0.1254, 0.8638, 0.8701, 0.2393, 0.3418, 0.9012,\n",
        "        0.9166, 0.5226, 0.6390, 0.0909, 0.3148, 0.8039, 0.0611, 0.9445, 0.6347,\n",
        "        0.4432, 0.2790, 0.2889, 0.9711, 0.1181, 0.4634, 0.7296, 0.7302, 0.0958,\n",
        "        0.3579, 0.9335, 0.0541, 0.5110, 0.9313, 0.9353, 0.8248, 0.7672, 0.8618,\n",
        "        0.2105, 0.2097, 0.3595, 0.9828, 0.8052, 0.5623, 0.4507, 0.8317, 0.6206,\n",
        "        0.8855, 0.4178, 0.6278, 0.9567, 0.6079, 0.1040, 0.4751, 0.2636, 0.3625,\n",
        "        0.5574, 0.0900, 0.9821, 0.8419, 0.2119, 0.6282, 0.6375, 0.8404, 0.5817,\n",
        "        0.0633, 0.1094, 0.8001, 0.1383, 0.6686, 0.9489, 0.1063, 0.2051, 0.2793,\n",
        "        0.3043, 0.5426, 0.2457, 0.4038, 0.2180, 0.1121, 0.6242, 0.4385, 0.4078,\n",
        "        0.6300, 0.1212, 0.8940, 0.7061, 0.7006, 0.5300, 0.8381, 0.0929, 0.2237,\n",
        "        0.6057, 0.6795, 0.3592, 0.1843, 0.8313, 0.9316, 0.4711, 0.7772, 0.3189,\n",
        "        0.9250, 0.5971, 0.6421, 0.4656, 0.0310, 0.9607, 0.7106, 0.6802, 0.3676,\n",
        "        0.6078, 0.4095, 0.5095, 0.3669, 0.7016, 0.5492, 0.0474, 0.7545, 0.2482,\n",
        "        0.3864, 0.9002, 0.3000, 0.5919, 0.1773, 0.4446, 0.1377, 0.2447, 0.9677,\n",
        "        0.1152, 0.4857, 0.8567, 0.3289, 0.3638, 0.8760, 0.3630, 0.2672, 0.0645,\n",
        "        0.1536, 0.6036, 0.8734, 0.3902, 0.3835, 0.9550, 0.8062, 0.0047, 0.8578,\n",
        "        0.8310, 0.8201, 0.2708, 0.0899, 0.9097, 0.2591, 0.5464, 0.6138, 0.5002,\n",
        "        0.1195, 0.1239, 0.6613, 0.6476, 0.0504, 0.0474, 0.0945, 0.0943, 0.1234,\n",
        "        0.3878, 0.1829, 0.9172, 0.1222, 0.1997, 0.5461, 0.8090, 0.5002, 0.0903,\n",
        "        0.7348, 0.7095, 0.8977, 0.5200, 0.6694, 0.3033, 0.5274, 0.3223, 0.9344,\n",
        "        0.3289, 0.6532, 0.1864, 0.9603, 0.7124, 0.8679, 0.1951, 0.2558, 0.6891,\n",
        "        0.4872, 0.3452, 0.8574, 0.6138, 0.7648, 0.0508, 0.1915, 0.6385, 0.2517,\n",
        "        0.0343, 0.9342, 0.0085, 0.1787, 0.9223, 0.5225, 0.4298, 0.8072, 0.1690,\n",
        "        0.4359, 0.4455, 0.3837, 0.5182, 0.6745, 0.6476, 0.7497, 0.0625, 0.8902,\n",
        "        0.5101, 0.5854, 0.9254, 0.3715, 0.6616, 0.9244, 0.0883, 0.9359, 0.5922,\n",
        "        0.6528, 0.5998, 0.7910, 0.6105, 0.4047, 0.1938, 0.6226, 0.3755, 0.4061,\n",
        "        0.6352, 0.2772, 0.8613, 0.7408, 0.4106, 0.7942, 0.7016, 0.8505, 0.6679,\n",
        "        0.2560, 0.0759, 0.6633, 0.1086, 0.7507, 0.6377, 0.2026, 0.0223, 0.3009,\n",
        "        0.0222, 0.2138, 0.3709, 0.9074, 0.2739, 0.7103, 0.8604, 0.8750, 0.0486,\n",
        "        0.0187, 0.9253, 0.2470, 0.6574, 0.0066, 0.6755, 0.4065, 0.9068, 0.4744,\n",
        "        0.5363, 0.9796, 0.3140, 0.4309, 0.8053, 0.8039, 0.9486, 0.9036, 0.0814,\n",
        "        0.9019, 0.8640, 0.7559, 0.4222, 0.7802, 0.6346, 0.5255, 0.8017, 0.3384,\n",
        "        0.8510, 0.5992, 0.1188, 0.8940, 0.6073, 0.7123, 0.5553, 0.7105, 0.3690,\n",
        "        0.5963, 0.4908, 0.8723, 0.3982, 0.6212, 0.2471, 0.2201, 0.4784, 0.3757,\n",
        "        0.9922, 0.4075, 0.2777, 0.7578, 0.5890, 0.9802, 0.9046, 0.0186, 0.0603,\n",
        "        0.5316, 0.2291, 0.6817, 0.9995, 0.2710, 0.5372, 0.4278, 0.7349, 0.8481,\n",
        "        0.0103, 0.7186, 0.3003, 0.0757, 0.5862, 0.8175, 0.4136, 0.9896, 0.1383,\n",
        "        0.6178, 0.4393, 0.7352, 0.6179, 0.4947, 0.9938, 0.6796, 0.5053, 0.5859,\n",
        "        0.6953, 0.8672, 0.6209, 0.6199, 0.0715, 0.0893, 0.5287, 0.3730, 0.4308,\n",
        "        0.1440, 0.7531, 0.1393, 0.8627, 0.3118, 0.5765, 0.3637, 0.2072, 0.4622,\n",
        "        0.7490, 0.1405, 0.5106, 0.5696, 0.9282, 0.3015, 0.8621, 0.0843, 0.3542,\n",
        "        0.1899, 0.9767, 0.6239, 0.0879, 0.2002, 0.8724, 0.8527, 0.1820, 0.0726,\n",
        "        0.6260, 0.9226, 0.6986, 0.8851, 0.8241, 0.6838, 0.4734, 0.1823, 0.3448,\n",
        "        0.0255, 0.5838, 0.8862, 0.7693, 0.7174, 0.6429, 0.3211, 0.7278, 0.1152,\n",
        "        0.3688, 0.5322, 0.5166, 0.9932, 0.2026, 0.5758, 0.5100, 0.9294, 0.5002,\n",
        "        0.0537, 0.4932, 0.1603, 0.7118, 0.5838, 0.3247, 0.1559, 0.4276, 0.1471,\n",
        "        0.2524, 0.9983, 0.7813, 0.3247, 0.0062, 0.7494, 0.4300, 0.9840, 0.2706,\n",
        "        0.9861, 0.6522, 0.7436, 0.0484, 0.2843, 0.8315, 0.7243, 0.7801, 0.7989,\n",
        "        0.5740, 0.0850, 0.3551, 0.5676, 0.2451, 0.4846, 0.6104, 0.6161, 0.3950,\n",
        "        0.9011, 0.3380, 0.1383, 0.6385, 0.6433, 0.5765, 0.9603, 0.7705, 0.5176,\n",
        "        0.9671, 0.1871, 0.2954, 0.1469, 0.8491, 0.0615, 0.3821, 0.5330, 0.3071,\n",
        "        0.6586, 0.4149, 0.6667, 0.9799, 0.9546, 0.5719, 0.3691, 0.2231, 0.1005,\n",
        "        0.2126, 0.6493, 0.1569, 0.4168, 0.8382, 0.4683, 0.8322, 0.5402, 0.0938,\n",
        "        0.9071, 0.6710, 0.5627, 0.5906, 0.2475, 0.9399, 0.8678, 0.1236, 0.5178,\n",
        "        0.5330, 0.5088, 0.9882, 0.5531, 0.8191, 0.7997, 0.3246, 0.8954, 0.5366,\n",
        "        0.8842, 0.5524, 0.7503, 0.5147, 0.1962, 0.0220, 0.5823, 0.8548, 0.6321,\n",
        "        0.6713, 0.5514, 0.9558, 0.7700, 0.3856, 0.9451, 0.0719, 0.0754, 0.2018,\n",
        "        0.9217, 0.5858, 0.0058, 0.9407, 0.6209, 0.7813, 0.1995, 0.9898, 0.5754,\n",
        "        0.6189, 0.8530, 0.5089, 0.9096, 0.0272, 0.4524, 0.1988, 0.8466, 0.4177,\n",
        "        0.0744, 0.8159, 0.7202, 0.2515, 0.0220, 0.3497, 0.2945, 0.6423, 0.8847,\n",
        "        0.9293, 0.0081, 0.6630, 0.5683, 0.3010, 0.6980, 0.2960, 0.2468, 0.4636,\n",
        "        0.2846, 0.1816, 0.9419, 0.4749, 0.6570, 0.4684, 0.1486, 0.1224, 0.4565,\n",
        "        0.7340, 0.1187, 0.6500, 0.2170, 0.4485, 0.0187, 0.2235, 0.0650, 0.2540,\n",
        "        0.1107, 0.2199, 0.4994, 0.9825, 0.5844, 0.0525, 0.6698, 0.2779, 0.7663,\n",
        "        0.8748, 0.5847, 0.7340, 0.7407, 0.4555, 0.6858, 0.1607, 0.0186, 0.4795,\n",
        "        0.9957, 0.5038, 0.9187, 0.4030, 0.9589, 0.5572, 0.4669, 0.9462, 0.0258,\n",
        "        0.6539, 0.6233, 0.9980, 0.0795, 0.0937, 0.6293, 0.6028, 0.2794, 0.9713,\n",
        "        0.3018, 0.7522, 0.6013, 0.9002, 0.5612, 0.6520, 0.5411, 0.0794, 0.0143,\n",
        "        0.4010, 0.0303, 0.4704, 0.8371, 0.4937, 0.4177, 0.0069, 0.0328, 0.6072,\n",
        "        0.2529, 0.5998, 0.2012, 0.2015, 0.5254, 0.2900, 0.9913, 0.9110, 0.5651,\n",
        "        0.9724, 0.5496, 0.0188, 0.1534, 0.4927, 0.4294, 0.8905, 0.3925, 0.4396,\n",
        "        0.9054, 0.1075, 0.9537, 0.3423, 0.2844, 0.0609, 0.8197, 0.0816, 0.5794,\n",
        "        0.9540, 0.2981, 0.0290, 0.6464, 0.2021, 0.0120, 0.9153, 0.2589, 0.1380,\n",
        "        0.3324, 0.4942, 0.4841, 0.9571, 0.8028, 0.1227, 0.4124, 0.0661, 0.5776,\n",
        "        0.8452, 0.4770, 0.0161, 0.8661, 0.1766, 0.1929, 0.2103, 0.8543, 0.5927,\n",
        "        0.7728, 0.7813, 0.2794, 0.0914, 0.6574, 0.4325, 0.7467, 0.7509, 0.6309,\n",
        "        0.6797, 0.6298, 0.8540, 0.7507, 0.4297, 0.1702, 0.3553, 0.2847, 0.6322,\n",
        "        0.7822, 0.3285, 0.2423, 0.4749, 0.2355, 0.6806, 0.8486, 0.9917, 0.4051,\n",
        "        0.7669, 0.2857, 0.7482, 0.7466, 0.0183, 0.4282, 0.2635, 0.0476, 0.8467,\n",
        "        0.2954, 0.1735, 0.3974, 0.6684, 0.8744, 0.4771, 0.3136, 0.9146, 0.2972,\n",
        "        0.8330])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([20177.8535, 20707.9180, 19930.0586, 18992.7129, 19726.8359, 21081.1953,\n",
            "        19399.6934, 19781.4336, 21394.1426, 18908.7441])\n"
          ]
        }
      ],
      "source": [
        "# Initialize the weights of the neural network\n",
        "weight_1 = torch.rand(784, 200)\n",
        "weight_2 = torch.rand(200, 10)\n",
        "\n",
        "# Multiply input_layer with weight_1\n",
        "hidden_1 = torch.matmul(input_layer, weight_1)\n",
        "\n",
        "# Multiply hidden_1 with weight_2\n",
        "output_layer = torch.matmul(hidden_1,weight_2)\n",
        "print(output_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        # Instantiate all 2 linear layers  \n",
        "        self.fc1 = nn.Linear(784, 200)\n",
        "        self.fc2 = nn.Linear(200, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "      \n",
        "        # Use the instantiated layers and return x\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Neural networks\n",
        "Let us see the differences between neural networks which apply ReLU and those which do not apply ReLU. We have already initialized the input called input_layer, and three sets of weights, called weight_1, weight_2 and weight_3.<br>\n",
        "We are going to convince ourselves that networks with multiple layers which do not contain non-linearity can be expressed as neural networks with one layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_layer=torch.tensor([[ 0.0401, -0.9005,  0.0397, -0.0876]])\n",
        "weight_1=torch.tensor([[-0.1094, -0.8285,  0.0416, -1.1222],\n",
        "        [ 0.3327, -0.0461,  1.4473, -0.8070],\n",
        "        [ 0.0681, -0.7058, -1.8017,  0.5857],\n",
        "        [ 0.8764,  0.9618, -0.4505,  0.2888]])\n",
        "weight_2=torch.tensor([[ 0.6856, -1.7650,  1.6375, -1.5759],\n",
        "        [-0.1092, -0.1620,  0.1951, -0.1169],\n",
        "        [-0.5120,  1.1997,  0.8483, -0.2476],\n",
        "        [-0.3369,  0.5617, -0.6658,  0.2221]])\n",
        "weight_3=torch.tensor([[ 0.8824,  0.1268,  1.1951,  1.3061],\n",
        "        [-0.8753, -0.3277, -0.1454, -0.0167],\n",
        "        [ 0.3582,  0.3254, -1.8509, -1.4205],\n",
        "        [ 0.3786,  0.5999, -0.5665, -0.3975]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.2653, 0.1311, 3.8219, 3.0032]])\n",
            "tensor([[0.2653, 0.1311, 3.8219, 3.0032]])\n"
          ]
        }
      ],
      "source": [
        "# Calculate the first and second hidden layer\n",
        "hidden_1 = torch.matmul(input_layer, weight_1)\n",
        "hidden_2 = torch.matmul(hidden_1, weight_2)\n",
        "\n",
        "# Calculate the output\n",
        "print(torch.matmul(hidden_2, weight_3))\n",
        "\n",
        "# Calculate weight_composed_1 and weight\n",
        "weight_composed_1 = torch.matmul(weight_1, weight_2)\n",
        "weight = torch.matmul(weight_composed_1, weight_3)\n",
        "\n",
        "# Multiply input_layer with weight\n",
        "print(torch.matmul(input_layer, weight))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ReLU activation\n",
        "In this exercise, we have the same settings as the previous exercise. But now we are going to build a neural network which has non-linearity. By doing so, we are going to convince ourselves that networks with multiple layers and non-linearity functions cannot be expressed as a neural network with one layer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.2770, -0.0345, -0.1410, -0.0664]])\n",
            "tensor([[-0.2117, -0.4782,  4.0438,  3.0417]])\n"
          ]
        }
      ],
      "source": [
        "# Instantiate non-linearity\n",
        "relu = nn.ReLU()\n",
        "\n",
        "# Apply non-linearity on the hidden layers\n",
        "hidden_1_activated = relu(torch.matmul(input_layer, weight_1))\n",
        "hidden_2_activated = relu(torch.matmul(hidden_1_activated, weight_2))\n",
        "print(torch.matmul(hidden_2_activated, weight_3))\n",
        "\n",
        "# Apply non-linearity in the product of first two weights. \n",
        "weight_composed_1_activated = relu(torch.matmul(weight_1, weight_2))\n",
        "\n",
        "# Multiply `weight_composed_1_activated` with `weight_3\n",
        "weight = torch.matmul(weight_composed_1_activated, weight_3)\n",
        "\n",
        "# Multiply input_layer with weight\n",
        "print(torch.matmul(input_layer, weight))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0., 0.]])\n"
          ]
        }
      ],
      "source": [
        "# Instantiate ReLU activation function as relu\n",
        "relu = nn.ReLU()\n",
        "\n",
        "# Initialize weight_1 and weight_2 with random numbers\n",
        "weight_1 = torch.rand(4, 6)\n",
        "weight_2 = torch.rand(6, 2)\n",
        "\n",
        "# Multiply input_layer with weight_1\n",
        "hidden_1 = torch.matmul(input_layer, weight_1)\n",
        "\n",
        "# Apply ReLU activation function over hidden_1 and multiply with weight_2\n",
        "hidden_1_activated = relu(hidden_1)\n",
        "print(torch.matmul(hidden_1_activated, weight_2))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calculating loss function in PyTorch\n",
        "You are going to code the previous exercise, and make sure that we computed the loss correctly. Predicted scores are -1.2 for class 0 (cat), 0.12 for class 1 (car) and 4.8 for class 2 (frog). The ground truth is class 2 (frog). Compute the loss function in PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0117)\n"
          ]
        }
      ],
      "source": [
        "# Initialize the scores and ground truth\n",
        "logits = torch.tensor([[-1.2, 0.12, 4.8]])\n",
        "ground_truth = torch.tensor([2])\n",
        "\n",
        "# Instantiate cross entropy loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Compute and print the loss\n",
        "loss = criterion(logits,ground_truth)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(7.0133)\n"
          ]
        }
      ],
      "source": [
        "# Initialize logits and ground truth\n",
        "logits = torch.rand(1,1000)\n",
        "ground_truth = torch.tensor([111])\n",
        "\n",
        "# Instantiate cross-entropy loss\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "\n",
        "# Calculate and print the loss\n",
        "loss = criterion(logits,ground_truth)\n",
        "print(loss)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preparing a dataset in PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "py",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "e5ec2996c563c234ac14e94a9194176f4b4a65942ae41358f6d1676f83052ec2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
