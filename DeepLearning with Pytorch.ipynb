{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDFVd-WfsEKx"
      },
      "source": [
        "# DeepLearning with Pytorch\n",
        "DataCamp Course"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NoMYOiXusEKy"
      },
      "outputs": [],
      "source": [
        "# pip install torch\n",
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyzwAgFAsrUU"
      },
      "source": [
        "## Creating tensors in PyTorch\n",
        "Random tensors are very important in neural networks. Parameters of the neural networks typically are initialized with random weights (random tensors).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2, 3, 5],\n",
              "        [1, 2, 9]])"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list1=[2,3,5]\n",
        "list2=[1,2,9]\n",
        "torch.tensor([list1,list2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[2, 3, 5],\n",
              "       [1, 2, 9]])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.array([list1,list2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.2116, 0.8931, 1.1053, 1.2417],\n",
              "        [0.7121, 1.8380, 1.7494, 1.6751],\n",
              "        [0.5606, 1.6617, 1.6932, 1.7045],\n",
              "        [0.6332, 1.7012, 1.6254, 1.6284]])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#multiplcation with pytorch\n",
        "mat1=torch.rand(4,4)\n",
        "mat2=torch.rand(4,4)\n",
        "multmat=torch.matmul(mat1,mat2)\n",
        "multmat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.0369, 0.1220, 0.1328, 0.7770],\n",
              "        [0.0877, 0.3180, 0.5295, 0.0727],\n",
              "        [0.3881, 0.4471, 0.4921, 0.4328],\n",
              "        [0.0460, 0.1642, 0.5739, 0.2692]])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#element multiplication\n",
        "mat1 * mat2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1.35642541, 1.01426486, 1.10246561, 0.78203579],\n",
              "       [0.55005192, 0.69566628, 0.65782618, 0.41660342],\n",
              "       [1.12589128, 1.12815996, 1.07644265, 0.99476697],\n",
              "       [1.16448307, 0.60912685, 0.9926406 , 0.43241657]])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#multiplication with Numpy\n",
        "mat1=np.random.rand(4,4)\n",
        "mat2=np.random.rand(4,4)\n",
        "multmat=np.dot(mat1,mat2)\n",
        "multmat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.58918873, 0.06954663, 0.21220215, 0.06804284],\n",
              "       [0.07824101, 0.11137922, 0.60596362, 0.10961892],\n",
              "       [0.02948115, 0.39719895, 0.38805566, 0.11387326],\n",
              "       [0.39490481, 0.12170485, 0.05764186, 0.09092363]])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#element multiplication\n",
        "np.multiply(mat1,mat2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0.],\n",
              "        [0., 0.]])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.zeros(2,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 1.],\n",
              "        [1., 1.]])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.ones(2,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 0.],\n",
              "        [0., 1.]])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.eye(2,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 0.],\n",
              "       [0., 0.]])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.zeros((2,2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1., 1.],\n",
              "       [1., 1.]])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.ones((2,2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1., 0.],\n",
              "       [0., 1.]])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.identity(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 0.],\n",
              "        [0., 1.]], dtype=torch.float64)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.from_numpy(np.identity(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1., 0.],\n",
              "       [0., 1.]], dtype=float32)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.eye(2,2).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "nOvj-7v_sEKz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.8301, 0.8794, 0.0787],\n",
            "        [0.1774, 0.1400, 0.9124],\n",
            "        [0.6530, 0.0886, 0.7491]])\n",
            "torch.Size([3, 3])\n"
          ]
        }
      ],
      "source": [
        "# Create random tensor of size 3 by 3\n",
        "your_first_tensor = torch.rand(3, 3)\n",
        "\n",
        "# Calculate the shape of the tensor\n",
        "tensor_size = your_first_tensor.shape\n",
        "\n",
        "# Print the values of the tensor and its shape\n",
        "print(your_first_tensor)\n",
        "print(tensor_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "EKamNVAHtUGl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.87257697 0.52333956 0.04170395]\n",
            " [0.60312084 0.81883652 0.75864398]\n",
            " [0.87435081 0.93170424 0.03689864]]\n",
            "(3, 3)\n"
          ]
        }
      ],
      "source": [
        "#same things in Numpy\n",
        "# Create random tensor of size 3 by 3\n",
        "your_first_tensor = np.random.rand(3, 3)\n",
        "\n",
        "# Calculate the shape of the tensor\n",
        "tensor_size = your_first_tensor.shape\n",
        "\n",
        "# Print the values of the tensor and its shape\n",
        "print(your_first_tensor)\n",
        "print(tensor_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "tensor([[1., 0., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 0., 1.]])\n"
          ]
        }
      ],
      "source": [
        "# Create a matrix of ones with shape 3 by 3\n",
        "tensor_of_ones = torch.ones(3, 3)\n",
        "\n",
        "# Create an identity matrix with shape 3 by 3\n",
        "identity_tensor = torch.eye(3)\n",
        "\n",
        "# Do a matrix multiplication of tensor_of_ones with identity_tensor\n",
        "matrices_multiplied = torch.matmul(tensor_of_ones, identity_tensor)\n",
        "print(matrices_multiplied)\n",
        "\n",
        "# Do an element-wise multiplication of tensor_of_ones with identity_tensor\n",
        "element_multiplication = tensor_of_ones*identity_tensor\n",
        "print(element_multiplication)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Forward pass\n",
        "Let's have something resembling more a neural network. The computational graph has been given below. You are going to initialize 3 large random tensors, and then do the operations as given in the computational graph. The final operation is the mean of the tensor, given by torch.mean(your_tensor)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(125066.8906)\n"
          ]
        }
      ],
      "source": [
        "# Initialize tensors x, y and z\n",
        "x = torch.rand(1000, 1000)\n",
        "y = torch.rand(1000, 1000)\n",
        "z = torch.rand(1000, 1000)\n",
        "\n",
        "# Multiply x with y\n",
        "q = torch.matmul(x,y)\n",
        "\n",
        "# Multiply elementwise z with q\n",
        "f = torch.matmul(z,q)\n",
        "\n",
        "mean_f = torch.mean(f)\n",
        "print(mean_f)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Backpropagation using PyTorch\n",
        "Here, you are going to use automatic differentiation of PyTorch in order to compute the derivatives of x, y and z from the previous exercise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradient of x is: tensor([5.])\n",
            "Gradient of y is: tensor([5.])\n",
            "Gradient of z is: tensor([1.])\n"
          ]
        }
      ],
      "source": [
        "# Initialize x, y and z to values 4, -3 and 5\n",
        "x = torch.tensor([4.], requires_grad=True)\n",
        "y = torch.tensor([-3.], requires_grad=True)\n",
        "z = torch.tensor([5.],requires_grad=True)\n",
        "\n",
        "# Set q to sum of x and y, set f to product of q with z\n",
        "q = x+y\n",
        "f = z*q\n",
        "\n",
        "# Compute the derivatives\n",
        "f.backward()\n",
        "\n",
        "# Print the gradients\n",
        "print(\"Gradient of x is: \" + str(x.grad))\n",
        "print(\"Gradient of y is: \" + str(y.grad))\n",
        "print(\"Gradient of z is: \" + str(z.grad))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradient of x is: tensor([[0.0388, 0.0440, 0.0600, 0.0617, 0.0295],\n",
            "        [0.0442, 0.0344, 0.0619, 0.0581, 0.0503],\n",
            "        [0.0196, 0.0207, 0.0326, 0.0462, 0.0269],\n",
            "        [0.0387, 0.0309, 0.0424, 0.0521, 0.0365],\n",
            "        [0.0201, 0.0224, 0.0437, 0.0581, 0.0374]])\n",
            "Gradient of y is: tensor([[0.0604, 0.0512, 0.0465, 0.0368, 0.0560],\n",
            "        [0.0522, 0.0516, 0.0422, 0.0489, 0.0645],\n",
            "        [0.0718, 0.0664, 0.0531, 0.0504, 0.0719],\n",
            "        [0.0385, 0.0365, 0.0311, 0.0253, 0.0380],\n",
            "        [0.0206, 0.0327, 0.0215, 0.0205, 0.0313]])\n",
            "Gradient of z is: tensor([[0.0213, 0.0432, 0.0611, 0.0159, 0.0261],\n",
            "        [0.0425, 0.0786, 0.1005, 0.0430, 0.0542],\n",
            "        [0.0435, 0.0418, 0.0730, 0.0370, 0.0364],\n",
            "        [0.0233, 0.0646, 0.0797, 0.0226, 0.0400],\n",
            "        [0.0229, 0.0630, 0.0884, 0.0131, 0.0435]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/vv/qbkrt9vj4_j3xx714txsmc900000gn/T/ipykernel_87158/1950033724.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = torch.tensor(torch.rand(5,5).requires_grad_(True), requires_grad=True)\n",
            "/var/folders/vv/qbkrt9vj4_j3xx714txsmc900000gn/T/ipykernel_87158/1950033724.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  y = torch.tensor(torch.rand(5,5).requires_grad_(True), requires_grad=True)\n",
            "/var/folders/vv/qbkrt9vj4_j3xx714txsmc900000gn/T/ipykernel_87158/1950033724.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  z = torch.tensor(torch.rand(5,5).requires_grad_(True),requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor(torch.rand(5,5).requires_grad_(True), requires_grad=True)\n",
        "y = torch.tensor(torch.rand(5,5).requires_grad_(True), requires_grad=True)\n",
        "z = torch.tensor(torch.rand(5,5).requires_grad_(True),requires_grad=True)\n",
        "\n",
        "# Multiply tensors x and y\n",
        "q = torch.matmul(x,y)\n",
        "\n",
        "# Elementwise multiply tensors z with q\n",
        "f = z*q\n",
        "\n",
        "mean_f = torch.mean(f)\n",
        "\n",
        "# Calculate the gradients\n",
        "mean_f.backward(\n",
        ")\n",
        "print(\"Gradient of x is: \" + str(x.grad))\n",
        "print(\"Gradient of y is: \" + str(y.grad))\n",
        "print(\"Gradient of z is: \" + str(z.grad))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradient of x is: tensor([[0.0494, 0.0418, 0.0150, 0.0242, 0.0162],\n",
            "        [0.0865, 0.0803, 0.0424, 0.0498, 0.0357],\n",
            "        [0.0456, 0.0341, 0.0288, 0.0348, 0.0290],\n",
            "        [0.1085, 0.1065, 0.0489, 0.0622, 0.0391],\n",
            "        [0.0541, 0.0514, 0.0329, 0.0403, 0.0276]])\n",
            "Gradient of y is: tensor([[0.0135, 0.0138, 0.0263, 0.0129, 0.0181],\n",
            "        [0.0255, 0.0299, 0.0336, 0.0349, 0.0406],\n",
            "        [0.0323, 0.0367, 0.0589, 0.0442, 0.0504],\n",
            "        [0.0513, 0.0421, 0.0738, 0.0452, 0.0621],\n",
            "        [0.0364, 0.0252, 0.0535, 0.0321, 0.0412]])\n",
            "Gradient of z is: tensor([[0.0512, 0.0348, 0.0283, 0.0448, 0.0364],\n",
            "        [0.0522, 0.0347, 0.0255, 0.0330, 0.0291],\n",
            "        [0.0806, 0.0467, 0.0436, 0.0773, 0.0437],\n",
            "        [0.0371, 0.0209, 0.0254, 0.0480, 0.0222],\n",
            "        [0.0327, 0.0222, 0.0199, 0.0359, 0.0226]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.rand(5,5).clone().detach().requires_grad_(True)\n",
        "y = torch.rand(5,5).clone().detach().requires_grad_(True)\n",
        "z = torch.rand(5,5).clone().detach().requires_grad_(True)\n",
        "\n",
        "# Multiply tensors x and y\n",
        "q = torch.matmul(x,y)\n",
        "\n",
        "# Elementwise multiply tensors z with q\n",
        "f = z*q\n",
        "\n",
        "mean_f = torch.mean(f)\n",
        "\n",
        "# Calculate the gradients\n",
        "mean_f.backward(\n",
        ")\n",
        "print(\"Gradient of x is: \" + str(x.grad))\n",
        "print(\"Gradient of y is: \" + str(y.grad))\n",
        "print(\"Gradient of z is: \" + str(z.grad))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction to Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net,self).__init__()\n",
        "        self.fc1=nn.Linear(10,20)\n",
        "        self.fc2=nn.Linear(20,20)\n",
        "        self.output=nn.Linear(20,4)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x=self.fc1(x)\n",
        "        x=self.fc2(x)\n",
        "        x=self.output(x)\n",
        "        return x"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Your first neural network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_layer=torch.tensor([0.6274, 0.1628, 0.0105, 0.6633, 0.8410, 0.9622, 0.5430, 0.1063, 0.9469,\n",
        "        0.6349, 0.4724, 0.8962, 0.4189, 0.1548, 0.1493, 0.8707, 0.5688, 0.5573,\n",
        "        0.0200, 0.0686, 0.4835, 0.6485, 0.6707, 0.4840, 0.3334, 0.4511, 0.9080,\n",
        "        0.7644, 0.1195, 0.2261, 0.7179, 0.0761, 0.3053, 0.4166, 0.5864, 0.7685,\n",
        "        0.1430, 0.5032, 0.7597, 0.0178, 0.6681, 0.7929, 0.2807, 0.4565, 0.8951,\n",
        "        0.9561, 0.7653, 0.6765, 0.9817, 0.6979, 0.7538, 0.9748, 0.7861, 0.9306,\n",
        "        0.9722, 0.9187, 0.8236, 0.9616, 0.7018, 0.0258, 0.0731, 0.9699, 0.7713,\n",
        "        0.4656, 0.9950, 0.3696, 0.1254, 0.8638, 0.8701, 0.2393, 0.3418, 0.9012,\n",
        "        0.9166, 0.5226, 0.6390, 0.0909, 0.3148, 0.8039, 0.0611, 0.9445, 0.6347,\n",
        "        0.4432, 0.2790, 0.2889, 0.9711, 0.1181, 0.4634, 0.7296, 0.7302, 0.0958,\n",
        "        0.3579, 0.9335, 0.0541, 0.5110, 0.9313, 0.9353, 0.8248, 0.7672, 0.8618,\n",
        "        0.2105, 0.2097, 0.3595, 0.9828, 0.8052, 0.5623, 0.4507, 0.8317, 0.6206,\n",
        "        0.8855, 0.4178, 0.6278, 0.9567, 0.6079, 0.1040, 0.4751, 0.2636, 0.3625,\n",
        "        0.5574, 0.0900, 0.9821, 0.8419, 0.2119, 0.6282, 0.6375, 0.8404, 0.5817,\n",
        "        0.0633, 0.1094, 0.8001, 0.1383, 0.6686, 0.9489, 0.1063, 0.2051, 0.2793,\n",
        "        0.3043, 0.5426, 0.2457, 0.4038, 0.2180, 0.1121, 0.6242, 0.4385, 0.4078,\n",
        "        0.6300, 0.1212, 0.8940, 0.7061, 0.7006, 0.5300, 0.8381, 0.0929, 0.2237,\n",
        "        0.6057, 0.6795, 0.3592, 0.1843, 0.8313, 0.9316, 0.4711, 0.7772, 0.3189,\n",
        "        0.9250, 0.5971, 0.6421, 0.4656, 0.0310, 0.9607, 0.7106, 0.6802, 0.3676,\n",
        "        0.6078, 0.4095, 0.5095, 0.3669, 0.7016, 0.5492, 0.0474, 0.7545, 0.2482,\n",
        "        0.3864, 0.9002, 0.3000, 0.5919, 0.1773, 0.4446, 0.1377, 0.2447, 0.9677,\n",
        "        0.1152, 0.4857, 0.8567, 0.3289, 0.3638, 0.8760, 0.3630, 0.2672, 0.0645,\n",
        "        0.1536, 0.6036, 0.8734, 0.3902, 0.3835, 0.9550, 0.8062, 0.0047, 0.8578,\n",
        "        0.8310, 0.8201, 0.2708, 0.0899, 0.9097, 0.2591, 0.5464, 0.6138, 0.5002,\n",
        "        0.1195, 0.1239, 0.6613, 0.6476, 0.0504, 0.0474, 0.0945, 0.0943, 0.1234,\n",
        "        0.3878, 0.1829, 0.9172, 0.1222, 0.1997, 0.5461, 0.8090, 0.5002, 0.0903,\n",
        "        0.7348, 0.7095, 0.8977, 0.5200, 0.6694, 0.3033, 0.5274, 0.3223, 0.9344,\n",
        "        0.3289, 0.6532, 0.1864, 0.9603, 0.7124, 0.8679, 0.1951, 0.2558, 0.6891,\n",
        "        0.4872, 0.3452, 0.8574, 0.6138, 0.7648, 0.0508, 0.1915, 0.6385, 0.2517,\n",
        "        0.0343, 0.9342, 0.0085, 0.1787, 0.9223, 0.5225, 0.4298, 0.8072, 0.1690,\n",
        "        0.4359, 0.4455, 0.3837, 0.5182, 0.6745, 0.6476, 0.7497, 0.0625, 0.8902,\n",
        "        0.5101, 0.5854, 0.9254, 0.3715, 0.6616, 0.9244, 0.0883, 0.9359, 0.5922,\n",
        "        0.6528, 0.5998, 0.7910, 0.6105, 0.4047, 0.1938, 0.6226, 0.3755, 0.4061,\n",
        "        0.6352, 0.2772, 0.8613, 0.7408, 0.4106, 0.7942, 0.7016, 0.8505, 0.6679,\n",
        "        0.2560, 0.0759, 0.6633, 0.1086, 0.7507, 0.6377, 0.2026, 0.0223, 0.3009,\n",
        "        0.0222, 0.2138, 0.3709, 0.9074, 0.2739, 0.7103, 0.8604, 0.8750, 0.0486,\n",
        "        0.0187, 0.9253, 0.2470, 0.6574, 0.0066, 0.6755, 0.4065, 0.9068, 0.4744,\n",
        "        0.5363, 0.9796, 0.3140, 0.4309, 0.8053, 0.8039, 0.9486, 0.9036, 0.0814,\n",
        "        0.9019, 0.8640, 0.7559, 0.4222, 0.7802, 0.6346, 0.5255, 0.8017, 0.3384,\n",
        "        0.8510, 0.5992, 0.1188, 0.8940, 0.6073, 0.7123, 0.5553, 0.7105, 0.3690,\n",
        "        0.5963, 0.4908, 0.8723, 0.3982, 0.6212, 0.2471, 0.2201, 0.4784, 0.3757,\n",
        "        0.9922, 0.4075, 0.2777, 0.7578, 0.5890, 0.9802, 0.9046, 0.0186, 0.0603,\n",
        "        0.5316, 0.2291, 0.6817, 0.9995, 0.2710, 0.5372, 0.4278, 0.7349, 0.8481,\n",
        "        0.0103, 0.7186, 0.3003, 0.0757, 0.5862, 0.8175, 0.4136, 0.9896, 0.1383,\n",
        "        0.6178, 0.4393, 0.7352, 0.6179, 0.4947, 0.9938, 0.6796, 0.5053, 0.5859,\n",
        "        0.6953, 0.8672, 0.6209, 0.6199, 0.0715, 0.0893, 0.5287, 0.3730, 0.4308,\n",
        "        0.1440, 0.7531, 0.1393, 0.8627, 0.3118, 0.5765, 0.3637, 0.2072, 0.4622,\n",
        "        0.7490, 0.1405, 0.5106, 0.5696, 0.9282, 0.3015, 0.8621, 0.0843, 0.3542,\n",
        "        0.1899, 0.9767, 0.6239, 0.0879, 0.2002, 0.8724, 0.8527, 0.1820, 0.0726,\n",
        "        0.6260, 0.9226, 0.6986, 0.8851, 0.8241, 0.6838, 0.4734, 0.1823, 0.3448,\n",
        "        0.0255, 0.5838, 0.8862, 0.7693, 0.7174, 0.6429, 0.3211, 0.7278, 0.1152,\n",
        "        0.3688, 0.5322, 0.5166, 0.9932, 0.2026, 0.5758, 0.5100, 0.9294, 0.5002,\n",
        "        0.0537, 0.4932, 0.1603, 0.7118, 0.5838, 0.3247, 0.1559, 0.4276, 0.1471,\n",
        "        0.2524, 0.9983, 0.7813, 0.3247, 0.0062, 0.7494, 0.4300, 0.9840, 0.2706,\n",
        "        0.9861, 0.6522, 0.7436, 0.0484, 0.2843, 0.8315, 0.7243, 0.7801, 0.7989,\n",
        "        0.5740, 0.0850, 0.3551, 0.5676, 0.2451, 0.4846, 0.6104, 0.6161, 0.3950,\n",
        "        0.9011, 0.3380, 0.1383, 0.6385, 0.6433, 0.5765, 0.9603, 0.7705, 0.5176,\n",
        "        0.9671, 0.1871, 0.2954, 0.1469, 0.8491, 0.0615, 0.3821, 0.5330, 0.3071,\n",
        "        0.6586, 0.4149, 0.6667, 0.9799, 0.9546, 0.5719, 0.3691, 0.2231, 0.1005,\n",
        "        0.2126, 0.6493, 0.1569, 0.4168, 0.8382, 0.4683, 0.8322, 0.5402, 0.0938,\n",
        "        0.9071, 0.6710, 0.5627, 0.5906, 0.2475, 0.9399, 0.8678, 0.1236, 0.5178,\n",
        "        0.5330, 0.5088, 0.9882, 0.5531, 0.8191, 0.7997, 0.3246, 0.8954, 0.5366,\n",
        "        0.8842, 0.5524, 0.7503, 0.5147, 0.1962, 0.0220, 0.5823, 0.8548, 0.6321,\n",
        "        0.6713, 0.5514, 0.9558, 0.7700, 0.3856, 0.9451, 0.0719, 0.0754, 0.2018,\n",
        "        0.9217, 0.5858, 0.0058, 0.9407, 0.6209, 0.7813, 0.1995, 0.9898, 0.5754,\n",
        "        0.6189, 0.8530, 0.5089, 0.9096, 0.0272, 0.4524, 0.1988, 0.8466, 0.4177,\n",
        "        0.0744, 0.8159, 0.7202, 0.2515, 0.0220, 0.3497, 0.2945, 0.6423, 0.8847,\n",
        "        0.9293, 0.0081, 0.6630, 0.5683, 0.3010, 0.6980, 0.2960, 0.2468, 0.4636,\n",
        "        0.2846, 0.1816, 0.9419, 0.4749, 0.6570, 0.4684, 0.1486, 0.1224, 0.4565,\n",
        "        0.7340, 0.1187, 0.6500, 0.2170, 0.4485, 0.0187, 0.2235, 0.0650, 0.2540,\n",
        "        0.1107, 0.2199, 0.4994, 0.9825, 0.5844, 0.0525, 0.6698, 0.2779, 0.7663,\n",
        "        0.8748, 0.5847, 0.7340, 0.7407, 0.4555, 0.6858, 0.1607, 0.0186, 0.4795,\n",
        "        0.9957, 0.5038, 0.9187, 0.4030, 0.9589, 0.5572, 0.4669, 0.9462, 0.0258,\n",
        "        0.6539, 0.6233, 0.9980, 0.0795, 0.0937, 0.6293, 0.6028, 0.2794, 0.9713,\n",
        "        0.3018, 0.7522, 0.6013, 0.9002, 0.5612, 0.6520, 0.5411, 0.0794, 0.0143,\n",
        "        0.4010, 0.0303, 0.4704, 0.8371, 0.4937, 0.4177, 0.0069, 0.0328, 0.6072,\n",
        "        0.2529, 0.5998, 0.2012, 0.2015, 0.5254, 0.2900, 0.9913, 0.9110, 0.5651,\n",
        "        0.9724, 0.5496, 0.0188, 0.1534, 0.4927, 0.4294, 0.8905, 0.3925, 0.4396,\n",
        "        0.9054, 0.1075, 0.9537, 0.3423, 0.2844, 0.0609, 0.8197, 0.0816, 0.5794,\n",
        "        0.9540, 0.2981, 0.0290, 0.6464, 0.2021, 0.0120, 0.9153, 0.2589, 0.1380,\n",
        "        0.3324, 0.4942, 0.4841, 0.9571, 0.8028, 0.1227, 0.4124, 0.0661, 0.5776,\n",
        "        0.8452, 0.4770, 0.0161, 0.8661, 0.1766, 0.1929, 0.2103, 0.8543, 0.5927,\n",
        "        0.7728, 0.7813, 0.2794, 0.0914, 0.6574, 0.4325, 0.7467, 0.7509, 0.6309,\n",
        "        0.6797, 0.6298, 0.8540, 0.7507, 0.4297, 0.1702, 0.3553, 0.2847, 0.6322,\n",
        "        0.7822, 0.3285, 0.2423, 0.4749, 0.2355, 0.6806, 0.8486, 0.9917, 0.4051,\n",
        "        0.7669, 0.2857, 0.7482, 0.7466, 0.0183, 0.4282, 0.2635, 0.0476, 0.8467,\n",
        "        0.2954, 0.1735, 0.3974, 0.6684, 0.8744, 0.4771, 0.3136, 0.9146, 0.2972,\n",
        "        0.8330])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([19978.9180, 21033.9336, 19594.5000, 20713.4941, 20507.1191, 21138.1641,\n",
            "        21083.0996, 19682.3438, 19563.5957, 20250.4043])\n"
          ]
        }
      ],
      "source": [
        "# Initialize the weights of the neural network\n",
        "weight_1 = torch.rand(784, 200)\n",
        "weight_2 = torch.rand(200, 10)\n",
        "\n",
        "# Multiply input_layer with weight_1\n",
        "hidden_1 = torch.matmul(input_layer, weight_1)\n",
        "\n",
        "# Multiply hidden_1 with weight_2\n",
        "output_layer = torch.matmul(hidden_1,weight_2)\n",
        "print(output_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        # Instantiate all 2 linear layers  \n",
        "        self.fc1 = nn.Linear(784, 200)\n",
        "        self.fc2 = nn.Linear(200, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "      \n",
        "        # Use the instantiated layers and return x\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Neural networks\n",
        "Let us see the differences between neural networks which apply ReLU and those which do not apply ReLU. We have already initialized the input called input_layer, and three sets of weights, called weight_1, weight_2 and weight_3.<br>\n",
        "We are going to convince ourselves that networks with multiple layers which do not contain non-linearity can be expressed as neural networks with one layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_layer=torch.tensor([[ 0.0401, -0.9005,  0.0397, -0.0876]])\n",
        "weight_1=torch.tensor([[-0.1094, -0.8285,  0.0416, -1.1222],\n",
        "        [ 0.3327, -0.0461,  1.4473, -0.8070],\n",
        "        [ 0.0681, -0.7058, -1.8017,  0.5857],\n",
        "        [ 0.8764,  0.9618, -0.4505,  0.2888]])\n",
        "weight_2=torch.tensor([[ 0.6856, -1.7650,  1.6375, -1.5759],\n",
        "        [-0.1092, -0.1620,  0.1951, -0.1169],\n",
        "        [-0.5120,  1.1997,  0.8483, -0.2476],\n",
        "        [-0.3369,  0.5617, -0.6658,  0.2221]])\n",
        "weight_3=torch.tensor([[ 0.8824,  0.1268,  1.1951,  1.3061],\n",
        "        [-0.8753, -0.3277, -0.1454, -0.0167],\n",
        "        [ 0.3582,  0.3254, -1.8509, -1.4205],\n",
        "        [ 0.3786,  0.5999, -0.5665, -0.3975]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.2653, 0.1311, 3.8219, 3.0032]])\n",
            "tensor([[0.2653, 0.1311, 3.8219, 3.0032]])\n"
          ]
        }
      ],
      "source": [
        "# Calculate the first and second hidden layer\n",
        "hidden_1 = torch.matmul(input_layer, weight_1)\n",
        "hidden_2 = torch.matmul(hidden_1, weight_2)\n",
        "\n",
        "# Calculate the output\n",
        "print(torch.matmul(hidden_2, weight_3))\n",
        "\n",
        "# Calculate weight_composed_1 and weight\n",
        "weight_composed_1 = torch.matmul(weight_1, weight_2)\n",
        "weight = torch.matmul(weight_composed_1, weight_3)\n",
        "\n",
        "# Multiply input_layer with weight\n",
        "print(torch.matmul(input_layer, weight))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ReLU activation\n",
        "In this exercise, we have the same settings as the previous exercise. But now we are going to build a neural network which has non-linearity. By doing so, we are going to convince ourselves that networks with multiple layers and non-linearity functions cannot be expressed as a neural network with one layer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.2770, -0.0345, -0.1410, -0.0664]])\n",
            "tensor([[-0.2117, -0.4782,  4.0438,  3.0417]])\n"
          ]
        }
      ],
      "source": [
        "# Instantiate non-linearity\n",
        "relu = nn.ReLU()\n",
        "\n",
        "# Apply non-linearity on the hidden layers\n",
        "hidden_1_activated = relu(torch.matmul(input_layer, weight_1))\n",
        "hidden_2_activated = relu(torch.matmul(hidden_1_activated, weight_2))\n",
        "print(torch.matmul(hidden_2_activated, weight_3))\n",
        "\n",
        "# Apply non-linearity in the product of first two weights. \n",
        "weight_composed_1_activated = relu(torch.matmul(weight_1, weight_2))\n",
        "\n",
        "# Multiply `weight_composed_1_activated` with `weight_3\n",
        "weight = torch.matmul(weight_composed_1_activated, weight_3)\n",
        "\n",
        "# Multiply input_layer with weight\n",
        "print(torch.matmul(input_layer, weight))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0., 0.]])\n"
          ]
        }
      ],
      "source": [
        "# Instantiate ReLU activation function as relu\n",
        "relu = nn.ReLU()\n",
        "\n",
        "# Initialize weight_1 and weight_2 with random numbers\n",
        "weight_1 = torch.rand(4, 6)\n",
        "weight_2 = torch.rand(6, 2)\n",
        "\n",
        "# Multiply input_layer with weight_1\n",
        "hidden_1 = torch.matmul(input_layer, weight_1)\n",
        "\n",
        "# Apply ReLU activation function over hidden_1 and multiply with weight_2\n",
        "hidden_1_activated = relu(hidden_1)\n",
        "print(torch.matmul(hidden_1_activated, weight_2))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calculating loss function in PyTorch\n",
        "You are going to code the previous exercise, and make sure that we computed the loss correctly. Predicted scores are -1.2 for class 0 (cat), 0.12 for class 1 (car) and 4.8 for class 2 (frog). The ground truth is class 2 (frog). Compute the loss function in PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0117)\n"
          ]
        }
      ],
      "source": [
        "# Initialize the scores and ground truth\n",
        "logits = torch.tensor([[-1.2, 0.12, 4.8]])\n",
        "ground_truth = torch.tensor([2])\n",
        "\n",
        "# Instantiate cross entropy loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Compute and print the loss\n",
        "loss = criterion(logits,ground_truth)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(6.5726)\n"
          ]
        }
      ],
      "source": [
        "# Initialize logits and ground truth\n",
        "logits = torch.rand(1,1000)\n",
        "ground_truth = torch.tensor([111])\n",
        "\n",
        "# Instantiate cross-entropy loss\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "\n",
        "# Calculate and print the loss\n",
        "loss = criterion(logits,ground_truth)\n",
        "print(loss)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preparing a dataset in PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pip install torchvision\n",
        "\n",
        "import torchvision\n",
        "import torch.utils.data\n",
        "#import torchvision.transforms as transforms\n",
        "from torchvision import transforms\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Transformation and Loading of CIFAR10 Dataset"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src='https://miro.medium.com/max/1182/1*OSvbuPLy0PSM2nZ62SbtlQ.png' width=\"500\" height=\"250\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "#\n",
        "transform=transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.48216, 0.44653),\n",
        "                         (0.24703, 0.24349, 0.26159))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "trainset=torchvision.datasets.CIFAR10(root='./Data',train=True, download=True, transform=transform)\n",
        "\n",
        "testset=torchvision.datasets.CIFAR10(root='./Data',train=False, download=True, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainloader=torch.utils.data.DataLoader(trainset, batch_size=32,\n",
        "                                        shuffle=True, num_workers=4)\n",
        "testloader=torch.utils.data.DataLoader(testset, batch_size=32,\n",
        "                                        shuffle=False, num_workers=4)                            "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Transformation and Loading of MNIST Dataset"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src='https://www.researchgate.net/publication/306056875/figure/fig1/AS:393921575309346@1470929630835/Example-images-from-the-MNIST-dataset.png' width=400 height=400>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You are going to prepare dataloaders for MNIST training and testing set. As we explained in the lecture, MNIST has some differences to CIFAR-10, with the main difference being that MNIST images are grayscale (1 channel based) instead of RGB (3 channels).<br>\n",
        "<li>Transform the data to torch tensors and normalize it to have mean is 0.1307 and std is 0.3081.</li>\n",
        "<li>Prepare the trainset and the testset.</li>\n",
        "<li>Prepare the dataloaders for training and testing so that only 32 pictures are processed at a time and the training data is shuffled each time.</li>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Transform the data to torch tensors and normalize it \n",
        "transform_ = transforms.Compose([transforms.ToTensor(),\n",
        "\t\t\t\t\t\t\t\ttransforms.Normalize((0.1307), ((0.3081)))])\n",
        "\n",
        "# Prepare training set and testing set\n",
        "train_set = torchvision.datasets.MNIST(root='./Data', train=True, \n",
        "\t\t\t\t\t\t\t\t\t  download=True, transform=transform_)\n",
        "test_set = torchvision.datasets.MNIST(root='./Data', train=False,\n",
        "\t\t\t   download=True, transform=transform_)\n",
        "\n",
        "# Prepare training loader and testing loader\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32,\n",
        "                                          shuffle=True, num_workers=0)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=32,\n",
        "\t\t\t\t\t\t\t\t\t\t shuffle=False, num_workers=0) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/hadi/opt/anaconda3/envs/py/lib/python3.9/site-packages/torchvision/datasets/mnist.py:75: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([60000, 28, 28])"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "train_loader.dataset.train_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/hadi/opt/anaconda3/envs/py/lib/python3.9/site-packages/torchvision/datasets/mnist.py:80: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([10000, 28, 28])"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_loader.dataset.test_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_loader.batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_loader.batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch.utils.data.sampler.RandomSampler at 0x7faea041e100>"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_loader.sampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([60000, 28, 28]) torch.Size([10000, 28, 28])\n",
            "32 32\n"
          ]
        }
      ],
      "source": [
        "# Compute the shape of the training set and testing set\n",
        "trainset_shape = trainloader.dataset.train_data.shape\n",
        "testset_shape = testloader.dataset.test_data.shape\n",
        "\n",
        "# Print the computed shapes\n",
        "print(trainset_shape, testset_shape)\n",
        "\n",
        "# Compute the size of the minibatch for training set and testing set\n",
        "trainset_batchsize = trainloader.batch_size\n",
        "testset_batchsize = testloader.batch_size\n",
        "\n",
        "# Print sizes of the minibatch\n",
        "print(trainset_batchsize, testset_batchsize)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training neural networks"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.nn import functional as F\n",
        "from torch import optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1=nn.Linear(32*32*3,500)\n",
        "        self.fc2=nn.Linear(500,10)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x= F.relu(self.fc1(x))\n",
        "        return self.fc2(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "net=Net()\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=optim.Adam(net.parameters(),lr=3e-4)\n",
        "\n",
        "for epoch in range(10): #loop over the dataset multiple times\n",
        "    for i, data in enumerate(trainloader,0):\n",
        "        #get the inputs\n",
        "        inputs, labels = data\n",
        "        inputs=inputs.view(-1, 32 * 32 * 3)\n",
        "\n",
        "        # Zero the parameter Gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #Forward + backward + optimize\n",
        "        outputs=net(inputs)\n",
        "        loss=criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the testing set accuracy of the network is : 52  %\n"
          ]
        }
      ],
      "source": [
        "correct, total = 0, 0\n",
        "predictions= []\n",
        "net.eval()\n",
        "for i, data in enumerate(testloader, 0):\n",
        "    inputs, labels = data\n",
        "    inputs = inputs.view(-1, 32 * 32 * 3)\n",
        "    outputs=net(inputs)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    predictions.append(outputs)\n",
        "    total +=labels.size(0)\n",
        "    correct +=(predicted==labels).sum().item()\n",
        "\n",
        "print(\"the testing set accuracy of the network is : %d  %%\" %(100 *correct/total))    "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the class Net\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):    \n",
        "    \t# Define all the parameters of the net\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28 * 1, 200)\n",
        "        self.fc2 = nn.Linear(200, 10)\n",
        "\n",
        "    def forward(self, x):   \n",
        "    \t# Do the forward pass\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Instantiate the Adam optimizer and Cross-Entropy loss function\n",
        "model = Net()   \n",
        "optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "  \n",
        "for batch_idx, data_target in enumerate(train_loader):\n",
        "    data = data_target[0]\n",
        "    target = data_target[1]\n",
        "    data = data.view(-1, 28 * 28)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Complete a forward pass\n",
        "    output = model(data)\n",
        "\n",
        "    # Compute the loss, gradients and change the weights\n",
        "    loss = criterion(output,target)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The testing set accuracy of the network is: 74 %\n"
          ]
        }
      ],
      "source": [
        "# Set the model in eval mode\n",
        "model.eval( )\n",
        "\n",
        "for i, data in enumerate(test_loader, 0):\n",
        "    inputs, labels = data\n",
        "    \n",
        "    # Put each image into a vector\n",
        "    inputs = inputs.view(-1, 28 * 28 * 1)\n",
        "    \n",
        "    # Do the forward pass and get the predictions\n",
        "    outputs = model(inputs)\n",
        "    _, outputs = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (outputs == labels).sum().item()\n",
        "print('The testing set accuracy of the network is: %d %%' % (100 * correct / total))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Convolution operator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([16, 1, 28, 28])\n",
            "torch.Size([16, 1, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "# OOP (torch.nn)\n",
        "# in_channels (int) number of chennels in inut\n",
        "# out_chennels (int) number of channels produced by the convolution\n",
        "# Kernel_size (int or tuple) size of the konvolving kernel\n",
        "# stride (int or tuple, optional) Stride of the convolution. Default:1\n",
        "# padding (int or tuple, optional) Zero padding\n",
        "image = torch.rand(16, 3, 32, 32)\n",
        "conv_filter = torch.nn.Conv2d(in_channels= 3, out_channels= 1,\n",
        "                                kernel_size= 5, stride= 1, padding= 0)\n",
        "output_feature = conv_filter(image)\n",
        "print(output_feature.shape)\n",
        "\n",
        "\n",
        "\n",
        "# functional (torch.nn.functional)\n",
        "# input - input tensor of shape (minibatch x in_channels x iH x iW)\n",
        "# weight - filters of shape (out_channels x in_channels x kH x kW)\n",
        "# stride - the stride of the convolving kernel. can be a single number or tuple (sH,sW). Default: 1\n",
        "# padding - implicit zero padding on both side of the input. can be s single number ot tuple (padH, padW). Default : 0\n",
        "\n",
        "image = torch.rand(16, 3, 32, 32)\n",
        "filter = torch.rand(1, 3, 5, 5)\n",
        "out_feat_F = F.conv2d(image, filter,\n",
        "                    stride= 1, padding = 0)\n",
        "print(out_feat_F.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([10, 6, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "# Convolution operator - OOP way\n",
        "\n",
        "# Create 10 images with shape (1, 28, 28).\n",
        "# Build 6 convolutional filters of size (3, 3) with stride set to 1 and padding set to 1.\n",
        "# Apply the filters in the image and print the shape of the feature map.\n",
        "\n",
        "# Create 10 random images of shape (1, 28, 28)\n",
        "images = torch.rand(10, 1, 28, 28)\n",
        "\n",
        "# Build 6 conv. filters\n",
        "conv_filters = torch.nn.Conv2d(in_channels=1, out_channels=6, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "# Convolve the image with the filters \n",
        "output_feature = conv_filters(images)\n",
        "print(output_feature.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([10, 6, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "# Convolution operator - Functional way\n",
        "# Create 10 random images with shape (1, 28, 28).\n",
        "# Create 6 random filters with shape (1, 3, 3).\n",
        "# Convolve the images with the filters.\n",
        "\n",
        "# Create 10 random images\n",
        "image = torch.rand(10, 1, 28, 28)\n",
        "\n",
        "# Create 6 filters\n",
        "filters = torch.rand(6, 1, 3, 3)\n",
        "\n",
        "# Convolve the image with the filters\n",
        "output_feature = F.conv2d(image, filters, stride=1, padding=1)\n",
        "print(output_feature.shape)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pooling operators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[6., 9.],\n",
            "         [3., 4.]]])\n",
            "tensor([[[2.5000, 6.0000],\n",
            "         [1.7500, 3.0000]]])\n",
            "tensor([[[6., 9.],\n",
            "         [3., 4.]]])\n",
            "tensor([[[2.5000, 6.0000],\n",
            "         [1.7500, 3.0000]]])\n"
          ]
        }
      ],
      "source": [
        "# OOP\n",
        "im = torch.Tensor([[[3, 1, 3, 5], [6, 0, 7, 9], [3, 2, 1, 4], [0, 2, 4, 3]]])\n",
        "# max pooling\n",
        "max_pooling = torch.nn.MaxPool2d(2)\n",
        "output_feature = max_pooling(im)\n",
        "print(output_feature)\n",
        "# average pooling\n",
        "avg_pooling = torch.nn.AvgPool2d(2)\n",
        "output_feature = avg_pooling(im)\n",
        "print(output_feature)\n",
        "\n",
        "\n",
        "# functional\n",
        "# Max\n",
        "output_feature_F = F.max_pool2d(im,2)\n",
        "print(output_feature_F)\n",
        "# average\n",
        "output_feature_F = F.avg_pool2d(im,2)\n",
        "print(output_feature_F)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[[8., 5., 9.],\n",
            "          [9., 2., 6.],\n",
            "          [2., 9., 8.]]]])\n",
            "tensor([[[[8., 5., 9.],\n",
            "          [9., 2., 6.],\n",
            "          [2., 9., 8.]]]])\n"
          ]
        }
      ],
      "source": [
        "tensor=torch.tensor([[[[ 8.,  1.,  2.,  5.,  3.,  1.],\n",
        "          [ 6.,  0.,  0., -5.,  7.,  9.],\n",
        "          [ 1.,  9., -1., -2.,  2.,  6.],\n",
        "          [ 0.,  4.,  2., -3.,  4.,  3.],\n",
        "          [ 2., -1.,  4., -1., -2.,  3.],\n",
        "          [ 2., -4.,  5.,  9., -7.,  8.]]]])\n",
        "\n",
        "\n",
        "# Build a pooling operator with size `2`.\n",
        "max_pooling = torch.nn.MaxPool2d(2)\n",
        "\n",
        "# Apply the pooling operator\n",
        "output_feature = max_pooling(tensor)\n",
        "\n",
        "# Use pooling operator in the image\n",
        "output_feature_F = F.max_pool2d(tensor,2)\n",
        "\n",
        "# print the results of both cases\n",
        "print(output_feature)\n",
        "print(output_feature_F)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[[ 3.7500,  0.5000,  5.0000],\n",
            "          [ 3.5000, -1.0000,  3.7500],\n",
            "          [-0.2500,  4.2500,  0.5000]]]])\n",
            "tensor([[[[ 3.7500,  0.5000,  5.0000],\n",
            "          [ 3.5000, -1.0000,  3.7500],\n",
            "          [-0.2500,  4.2500,  0.5000]]]])\n"
          ]
        }
      ],
      "source": [
        "# Build a pooling operator with size `2`.\n",
        "avg_pooling = torch.nn.AvgPool2d(2)\n",
        "\n",
        "# Apply the pooling operator\n",
        "output_feature = avg_pooling(tensor)\n",
        "\n",
        "# Use pooling operator in the image\n",
        "output_feature_F = F.avg_pool2d(tensor,2)\n",
        "\n",
        "# print the results of both cases\n",
        "print(output_feature)\n",
        "print(output_feature_F)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Convolutional Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "py",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "e5ec2996c563c234ac14e94a9194176f4b4a65942ae41358f6d1676f83052ec2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
